{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRxoWDrS5DyI"
      },
      "source": [
        "๐ Step 1: Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMAd2Ybb5KwJ"
      },
      "outputs": [],
      "source": [
        "import json # for dealing with Json files\n",
        "import pandas as pd # for dealing with dataset\n",
        "import csv # used to wirte the data in CVS file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtOgs4li5Iuw"
      },
      "source": [
        "Convert Json data to CVS file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inY4O3KxA2Dl"
      },
      "outputs": [],
      "source": [
        "# The pass to the Json dataset (old)\n",
        "input_file = 'labeled_validation_dataset.jsonl'\n",
        "# The pass to the CSV dataset (new)\n",
        "output_file = 'labeled_validation_dataset.csv'\n",
        "\n",
        "# Read from the Json file and write in the CSV file\n",
        "with open(input_file, 'r', encoding='utf-8') as input, open(output_file, 'w', encoding='utf-8', newline='') as output:\n",
        "    # Write the rows in csv\n",
        "    writer = csv.writer(output)\n",
        "    # Create column names\n",
        "    writer.writerow(['paragraph', 'summary'])\n",
        "\n",
        "    # Loop on the input file and copy his content into output file\n",
        "    for line in input:\n",
        "        # Load the lines from Json data\n",
        "        data = json.loads(line)\n",
        "        # Copy the data\n",
        "        paragraph = data['paragraph']\n",
        "        summary = data['summary']\n",
        "\n",
        "        # Write the extracted data to the output file\n",
        "        writer.writerow([paragraph, summary])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOwUrKeFA5G2"
      },
      "source": [
        "load csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Q5dCCXlFHij5",
        "outputId": "19b0fe9e-60b8-4829-a61f-2db76dcbdcdc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           paragraph  \\\n",
              "0  ูุชุญุช ุนููุงู ูู ุงููุงุฑุซุฉ ุฅูู ุงูุชุญุฏู ูุจุฏุฃ ุงููุงุชุจ ุน...   \n",
              "1  ููู ูุนุชุฑู ุฏุจูููุงุณูู ูุงุชูู ุงูุฏููุชูู ุจุงูุนุฑูุถุฉ ุงู...   \n",
              "2  ูุงูุช ููุงูุฉ ุญูุจ ุจุนุฏ ุงุนูุงู ุงูุฌูุฑุงู ุงููุฑูุณู ููุฑู ...   \n",
              "3  ุฏููุฉ ูุตุฑ ุงูุนุฑุจูู ูู ููุณุช ุงู ุฏููู ูููุณุช ุงู ุดุนุจ ...   \n",
              "4  ุงูุณูุฑููู ูุตุฑูู ุนูู ุงุณุชููุงู ุจูุงุฏูู : ู ูุซููุง ุฑู...   \n",
              "\n",
              "                                             summary  \n",
              "0  ูุจุฏุฃ ุงููุงุชุจ ุนุฑุถ ุงููุชุงุจ ุงูุฑุงุจุน ุชุญุช ุนููุงู ูู ุงูู...  \n",
              "1  ุฏุจูููุงุณูู ุงูุฏููุชูู ูู ูุนุชุฑููุง ุจุงูุนุฑูุถุฉ ุงูุชู ูุง...  \n",
              "2  ุฃุนูู ุบูุฑู ุงูุงูุชุฏุงุจ ุงููุฑูุณู ุนูู ุณูุฑูุง ููู ูุนุงูุจ...  \n",
              "3  ูุตุฑ ูู ุฃู ุงูุจูุงุฏุ ููุงุฆุฏุฉ ุงูุนุฑุจุ ููู ุฃุฑุถ ุจูุงุฏ ุง...  \n",
              "4  ุงูุดุนุจ ุงูุณูุฑู ูุตุฑ ุนูู ุงุณุชููุงู ุจูุฏูู ูู ุงูุณูุทุฑุฉ ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15b98e16-7799-4682-a2c9-93cdb6d4f3a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paragraph</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ูุชุญุช ุนููุงู ูู ุงููุงุฑุซุฉ ุฅูู ุงูุชุญุฏู ูุจุฏุฃ ุงููุงุชุจ ุน...</td>\n",
              "      <td>ูุจุฏุฃ ุงููุงุชุจ ุนุฑุถ ุงููุชุงุจ ุงูุฑุงุจุน ุชุญุช ุนููุงู ูู ุงูู...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ููู ูุนุชุฑู ุฏุจูููุงุณูู ูุงุชูู ุงูุฏููุชูู ุจุงูุนุฑูุถุฉ ุงู...</td>\n",
              "      <td>ุฏุจูููุงุณูู ุงูุฏููุชูู ูู ูุนุชุฑููุง ุจุงูุนุฑูุถุฉ ุงูุชู ูุง...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ูุงูุช ููุงูุฉ ุญูุจ ุจุนุฏ ุงุนูุงู ุงูุฌูุฑุงู ุงููุฑูุณู ููุฑู ...</td>\n",
              "      <td>ุฃุนูู ุบูุฑู ุงูุงูุชุฏุงุจ ุงููุฑูุณู ุนูู ุณูุฑูุง ููู ูุนุงูุจ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ุฏููุฉ ูุตุฑ ุงูุนุฑุจูู ูู ููุณุช ุงู ุฏููู ูููุณุช ุงู ุดุนุจ ...</td>\n",
              "      <td>ูุตุฑ ูู ุฃู ุงูุจูุงุฏุ ููุงุฆุฏุฉ ุงูุนุฑุจุ ููู ุฃุฑุถ ุจูุงุฏ ุง...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ุงูุณูุฑููู ูุตุฑูู ุนูู ุงุณุชููุงู ุจูุงุฏูู : ู ูุซููุง ุฑู...</td>\n",
              "      <td>ุงูุดุนุจ ุงูุณูุฑู ูุตุฑ ุนูู ุงุณุชููุงู ุจูุฏูู ูู ุงูุณูุทุฑุฉ ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15b98e16-7799-4682-a2c9-93cdb6d4f3a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15b98e16-7799-4682-a2c9-93cdb6d4f3a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15b98e16-7799-4682-a2c9-93cdb6d4f3a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Read the new dataset that we was created in the above\n",
        "reviews = pd.read_csv('/content/labeled_validation_dataset.csv')\n",
        "# display the dataset\n",
        "reviews.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjTPMD1kBHu9"
      },
      "source": [
        "# ๐ Step 2: Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dmc3zsKBJfE",
        "outputId": "0cdca49d-f9e6-420c-cf30-81039db4b79d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 154 entries, 0 to 153\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   paragraph  154 non-null    object\n",
            " 1   summary    154 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 2.5+ KB\n"
          ]
        }
      ],
      "source": [
        "reviews.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkeUdknLBNJy",
        "outputId": "226baeea-2b93-4053-dcdd-0b4ba9a1196c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(154, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "reviews.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvE-NbI2BTDx"
      },
      "source": [
        "### Number of tokens in a text\n",
        "> split text to tokens\n",
        "\n",
        "    - applies the split() method to each element in the 'text' column.\n",
        "    - It splits the text into a list of tokens,\n",
        "\n",
        "> mapping lambda function\n",
        "\n",
        "    - applies the map() method for each token in the text,\n",
        "    - it calculates the length of the token using len(i)\n",
        "\n",
        "> final result\n",
        "\n",
        "    - dataset_train['no_tokens']= stores the lengths of the words for each text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEMdKdlTBeT4"
      },
      "source": [
        "create column from number of tokens paragraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "rzuSy4_wBXMa",
        "outputId": "3ea1747a-80ff-472d-fe2f-e389d4f0ad45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             paragraph  \\\n",
              "93   ูููุง ููู ุงููุณุชูุตุฑ ุณูุฉ 427 ู ุฃุตุจุญ ุงูุฌูุฏ ุทุงุฆูุชูู...   \n",
              "41   ุฃูุง ุจุฎุตูุต ุงูุชูุธูู ูุงูููุงุฑุณุงุช ุงูุฅุฏุงุฑูุฉ ุงููุญููุฉ ...   \n",
              "152  ููู ุชูุชุตุฑ ููููุงุช ุจูุฑุณุนูุฏ ููุฏููุฉ ุนุงูููุฉ ููุฐ ูุดุฃ...   \n",
              "97   ููุณ ููุงู ุงุชูุงู ุจูู ุงูุจุงุญุซูู ุนู ูุจุฏุฃ ููุงู ูุฐู ุง...   \n",
              "123  ููู ุดูุฑ ุฃุบุณุทุณ ุนุงู 1939 ู ูุฏูุช ูุฒุงุฑุฉ ูุญูุฏ ูุญููุฏ...   \n",
              "103  ูุงูุช ูุตุฑ ุจููุน ุงูุณูู ุงูุงุณุฑุงุฆูููุฉ ูู ุฃุณุชุฎุฏุงู ููุง...   \n",
              "83   ุนุดูุฉ ุงูููุงุฑ ุงูุณูุทูุฉ ุงูุนุซูุงููุฉ ุ ูุงูุช ุงูุซูุฑุฉ ุงู...   \n",
              "8    ููุงู ููุจุทู ูุญูุฏ ุนูู ูููู ุจุนุถ ุงูุนูููุงุช ุงููุงูุฉ ู...   \n",
              "17   ูู ุชูู ุชูู ูู ุงููุฑุฉ ุงูุฃููู ุงูุชู ุชุชุนุฑุถ ูููุง ุตูู...   \n",
              "29   ููุงูุช ุงูุณูุงุณุฉ ุงูุชุฑููุฉ ูุชุฑุฏุฏุฉ ุบูุฑ ูุณุชูุฑุฉ ุ ุชุฑูุจ...   \n",
              "\n",
              "                                               summary  tokens_paragraph  \n",
              "93   ุนูุฏูุง ุชููู ุงููุณุชูุตุฑ ุงูุญูู ุฃุตุจุญ ุงูุฌูุฏ ุทุงุฆูุชููุ ...               385  \n",
              "41   ุฌุนู ุงูุฅูุจุฑุงุทูุฑ ุฃุบุณุทุณ ูุตุฑ ุฃุดุจู ุจุถูุนุฉ ุฎุงุตุฉ ุจู ุญุช...               301  \n",
              "152  ุงูุชุฏุช ุจูุฑุณุนูุฏ ููู ุชุดูู ุงูุทุงุจุน ุงูุซูุงูู ูููุฏููุฉุ...               356  \n",
              "97   ุงุฎุชูู ุงูุจุงุญุซูู ุญูู ุจุฏุงูุฉ ููุงู ูุฐู ุงูููููุฉ, ููู...               293  \n",
              "123  ูุฒุงุฑุฉ ูุญูุฏ ุจุงุดุง ูุฏูุช ุงุณุชูุงูุชูุง ููููู ูุงุฑููุ ูู...               383  \n",
              "103  ููุนุช ูุตุฑ ุงุณุฑุงุฆูู ูู ุงูููุงุญุฉ ูู ุงูููุงุฉ ูุชุตุงุนุฏุช ...               384  \n",
              "83   ุจุนุฏ ุทุฑุฏ ุงูุฃุชุฑุงูุ ุฃุธูุฑุช ุงูุซูุฑุฉ ุงูุฑุบุจุฉ ุจุงูุชุฎูุต ู...               330  \n",
              "8    ูุงู ููุจุทู ูุญูุฏ ุนูู ูููู ุจุนุถ ุงูุนูููุงุช ุงููููุฉ ุงู...               374  \n",
              "17   ููุฐ ูุฌุฑ ุงูุชุงุฑูุฎ ููู ุชุฏุงุนุจ ุฃูุธุงุฑ ุงูุบุฒุงุฉ ููู ุงูุฌ...               349  \n",
              "29   ูุงูุช ุณูุงุณุฉ ุชุฑููุง ูุดุฉ ุชุฑุงูุจ ูุตุฑ ุซู ุชุตุฏุฑ ุงููุฑุงุฑ ...               303  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8309ee3a-cab0-4e3e-bd4d-c18fed103552\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paragraph</th>\n",
              "      <th>summary</th>\n",
              "      <th>tokens_paragraph</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>ูููุง ููู ุงููุณุชูุตุฑ ุณูุฉ 427 ู ุฃุตุจุญ ุงูุฌูุฏ ุทุงุฆูุชูู...</td>\n",
              "      <td>ุนูุฏูุง ุชููู ุงููุณุชูุตุฑ ุงูุญูู ุฃุตุจุญ ุงูุฌูุฏ ุทุงุฆูุชููุ ...</td>\n",
              "      <td>385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>ุฃูุง ุจุฎุตูุต ุงูุชูุธูู ูุงูููุงุฑุณุงุช ุงูุฅุฏุงุฑูุฉ ุงููุญููุฉ ...</td>\n",
              "      <td>ุฌุนู ุงูุฅูุจุฑุงุทูุฑ ุฃุบุณุทุณ ูุตุฑ ุฃุดุจู ุจุถูุนุฉ ุฎุงุตุฉ ุจู ุญุช...</td>\n",
              "      <td>301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>ููู ุชูุชุตุฑ ููููุงุช ุจูุฑุณุนูุฏ ููุฏููุฉ ุนุงูููุฉ ููุฐ ูุดุฃ...</td>\n",
              "      <td>ุงูุชุฏุช ุจูุฑุณุนูุฏ ููู ุชุดูู ุงูุทุงุจุน ุงูุซูุงูู ูููุฏููุฉุ...</td>\n",
              "      <td>356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>ููุณ ููุงู ุงุชูุงู ุจูู ุงูุจุงุญุซูู ุนู ูุจุฏุฃ ููุงู ูุฐู ุง...</td>\n",
              "      <td>ุงุฎุชูู ุงูุจุงุญุซูู ุญูู ุจุฏุงูุฉ ููุงู ูุฐู ุงูููููุฉ, ููู...</td>\n",
              "      <td>293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>ููู ุดูุฑ ุฃุบุณุทุณ ุนุงู 1939 ู ูุฏูุช ูุฒุงุฑุฉ ูุญูุฏ ูุญููุฏ...</td>\n",
              "      <td>ูุฒุงุฑุฉ ูุญูุฏ ุจุงุดุง ูุฏูุช ุงุณุชูุงูุชูุง ููููู ูุงุฑููุ ูู...</td>\n",
              "      <td>383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>ูุงูุช ูุตุฑ ุจููุน ุงูุณูู ุงูุงุณุฑุงุฆูููุฉ ูู ุฃุณุชุฎุฏุงู ููุง...</td>\n",
              "      <td>ููุนุช ูุตุฑ ุงุณุฑุงุฆูู ูู ุงูููุงุญุฉ ูู ุงูููุงุฉ ูุชุตุงุนุฏุช ...</td>\n",
              "      <td>384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>ุนุดูุฉ ุงูููุงุฑ ุงูุณูุทูุฉ ุงูุนุซูุงููุฉ ุ ูุงูุช ุงูุซูุฑุฉ ุงู...</td>\n",
              "      <td>ุจุนุฏ ุทุฑุฏ ุงูุฃุชุฑุงูุ ุฃุธูุฑุช ุงูุซูุฑุฉ ุงูุฑุบุจุฉ ุจุงูุชุฎูุต ู...</td>\n",
              "      <td>330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ููุงู ููุจุทู ูุญูุฏ ุนูู ูููู ุจุนุถ ุงูุนูููุงุช ุงููุงูุฉ ู...</td>\n",
              "      <td>ูุงู ููุจุทู ูุญูุฏ ุนูู ูููู ุจุนุถ ุงูุนูููุงุช ุงููููุฉ ุงู...</td>\n",
              "      <td>374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ูู ุชูู ุชูู ูู ุงููุฑุฉ ุงูุฃููู ุงูุชู ุชุชุนุฑุถ ูููุง ุตูู...</td>\n",
              "      <td>ููุฐ ูุฌุฑ ุงูุชุงุฑูุฎ ููู ุชุฏุงุนุจ ุฃูุธุงุฑ ุงูุบุฒุงุฉ ููู ุงูุฌ...</td>\n",
              "      <td>349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>ููุงูุช ุงูุณูุงุณุฉ ุงูุชุฑููุฉ ูุชุฑุฏุฏุฉ ุบูุฑ ูุณุชูุฑุฉ ุ ุชุฑูุจ...</td>\n",
              "      <td>ูุงูุช ุณูุงุณุฉ ุชุฑููุง ูุดุฉ ุชุฑุงูุจ ูุตุฑ ุซู ุชุตุฏุฑ ุงููุฑุงุฑ ...</td>\n",
              "      <td>303</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8309ee3a-cab0-4e3e-bd4d-c18fed103552')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8309ee3a-cab0-4e3e-bd4d-c18fed103552 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8309ee3a-cab0-4e3e-bd4d-c18fed103552');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "reviews['tokens_paragraph']= reviews['paragraph'].str.split().map(lambda token: len(token))\n",
        "reviews.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSeC6N5PBo0-"
      },
      "source": [
        "visualize tokens paragraph as histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25ot0RdTB8ob"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt # make visualization\n",
        "import seaborn as sns # make visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "51AwRuQABnn3",
        "outputId": "adb75525-9334-401a-994e-0ffee9ef6889"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "reviews['tokens_paragraph'].plot(bins=35,\n",
        "                            kind='hist',\n",
        "                            color='red',\n",
        "                            label='paragraph',\n",
        "                            alpha=0.6)\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel(\"Numbers of tokens\")\n",
        "plt.ylabel(\"Numbers of texts\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scYcxNKYCHJ7"
      },
      "source": [
        "max tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f4zN33-CKhi",
        "outputId": "24b4709f-13f1-4c38-d0ee-25c1fbce355a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "max_tokens= reviews['tokens_paragraph'].max()\n",
        "max_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQmazBV1CMmp"
      },
      "source": [
        "show max tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JjXgsuUCPlT",
        "outputId": "7bc11e14-7319-4ff9-b4b8-36249c6655e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116    ูุจุนุฏ ุฃู ูุงูุช ุญูููุฉ ุงูููุฏ ุจุฅูุบุงุก ูุนุงูุฏุฉ ุนุงู 193...\n",
              "Name: paragraph, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "reviews[reviews['tokens_paragraph'] == max_tokens]['paragraph']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yycJn9KNCSLb"
      },
      "source": [
        "# Step 3: Translate pharagraph & Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39txgWvpt7yy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d422ffe-7c86-434c-ebac-946fe4030f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mtranslate\n",
            "  Downloading mtranslate-1.8.tar.gz (2.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mtranslate\n",
            "  Building wheel for mtranslate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mtranslate: filename=mtranslate-1.8-py3-none-any.whl size=3671 sha256=39761f235d49e59b7393d4234df7a166ab1b6fc5c2984a476b033e14a1c65294\n",
            "  Stored in directory: /root/.cache/pip/wheels/c2/04/15/d7654c2c4a9a52e09922967593f3278fed66059be65ca671ea\n",
            "Successfully built mtranslate\n",
            "Installing collected packages: mtranslate\n",
            "Successfully installed mtranslate-1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install mtranslate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5nBz1Nft3R_"
      },
      "outputs": [],
      "source": [
        "# Use Microsoft edge\n",
        "from mtranslate import translate\n",
        "\n",
        "# Arabic-to-English Translation\n",
        "def translate_ar_to_en(text):\n",
        "    translated_text = translate(text, \"en\", \"ar\")\n",
        "    return translated_text\n",
        "\n",
        "# English-to-Arabic Translation\n",
        "def translate_en_to_ar(text):\n",
        "    translated_text = translate(text, \"ar\", \"en\")\n",
        "    return translated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIALYXwiwNMe",
        "outputId": "63fadbdd-de00-4922-8478-230e33047c8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I am Ahmed Khattab, a student at the Russian University in Egypt\n"
          ]
        }
      ],
      "source": [
        "x = translate_ar_to_en('ูุฑุญุจุง ุจูู ุงูุง ุงุญูุฏ ุฎุทุงุจ ุทุงูุจ ูู ุงูุฌุงูุนู ุงูุฑูุณูู ุจูุตุฑ')\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFqHNwdzpAEY",
        "outputId": "fedb3299-605c-4f4b-c21e-afe71900f5bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ูุฑุญุจุงู ุ ุฃูุง ุฃุญูุฏ ุฎุทุงุจ ุทุงูุจ ูู ุงูุฌุงูุนุฉ ุงูุฑูุณูุฉ ูู ูุตุฑ\n"
          ]
        }
      ],
      "source": [
        "y = translate_en_to_ar(x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxS_TuCvv3gF"
      },
      "source": [
        "# Translate the input_text to English"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwsDAvQsVfuH",
        "outputId": "52f13664-e89d-4030-c8fc-7e190fc955d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - 11 - 12 - 13 - 14 - 15 - 16 - 17 - 18 - 19 - 20 - 21 - 22 - 23 - 24 - 25 - 26 - 27 - 28 - 29 - 30 - 31 - 32 - 33 - 34 - 35 - 36 - 37 - 38 - 39 - 40 - 41 - 42 - 43 - 44 - 45 - 46 - 47 - 48 - 49 - 50 - 51 - 52 - 53 - 54 - 55 - 56 - 57 - 58 - 59 - 60 - 61 - 62 - 63 - 64 - 65 - 66 - 67 - 68 - 69 - 70 - 71 - 72 - 73 - 74 - 75 - 76 - 77 - 78 - 79 - 80 - 81 - 82 - 83 - 84 - 85 - 86 - 87 - 88 - 89 - 90 - 91 - 92 - 93 - 94 - 95 - 96 - 97 - 98 - 99 - 100 - 101 - 102 - 103 - 104 - 105 - 106 - 107 - 108 - 109 - 110 - 111 - 112 - 113 - 114 - 115 - 116 - 117 - 118 - 119 - 120 - 121 - 122 - 123 - 124 - 125 - 126 - 127 - 128 - 129 - 130 - 131 - 132 - 133 - 134 - 135 - 136 - 137 - 138 - 139 - 140 - 141 - 142 - 143 - 144 - 145 - 146 - 147 - 148 - 149 - 150 - 151 - 152 - 153 - Done\n"
          ]
        }
      ],
      "source": [
        "arabic_translation_list = []\n",
        "i = 0\n",
        "for text in reviews['paragraph']:\n",
        "    english_text = text\n",
        "    arabic_translation = translate_ar_to_en(english_text)\n",
        "    arabic_translation_list.append(arabic_translation)\n",
        "    print(i,end=' - ')\n",
        "    i+=1\n",
        "\n",
        "reviews['translated_input'] = arabic_translation_list\n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yziZeSqv8tB"
      },
      "source": [
        "# Translate the target_text to English"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHX95QXavTYW",
        "outputId": "33a46685-11d8-4381-dfd3-b955ab65e487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - 11 - 12 - 13 - 14 - 15 - 16 - 17 - 18 - 19 - 20 - 21 - 22 - 23 - 24 - 25 - 26 - 27 - 28 - 29 - 30 - 31 - 32 - 33 - 34 - 35 - 36 - 37 - 38 - 39 - 40 - 41 - 42 - 43 - 44 - 45 - 46 - 47 - 48 - 49 - 50 - 51 - 52 - 53 - 54 - 55 - 56 - 57 - 58 - 59 - 60 - 61 - 62 - 63 - 64 - 65 - 66 - 67 - 68 - 69 - 70 - 71 - 72 - 73 - 74 - 75 - 76 - 77 - 78 - 79 - 80 - 81 - 82 - 83 - 84 - 85 - 86 - 87 - 88 - 89 - 90 - 91 - 92 - 93 - 94 - 95 - 96 - 97 - 98 - 99 - 100 - 101 - 102 - 103 - 104 - 105 - 106 - 107 - 108 - 109 - 110 - 111 - 112 - 113 - 114 - 115 - 116 - 117 - 118 - 119 - 120 - 121 - 122 - 123 - 124 - 125 - 126 - 127 - 128 - 129 - 130 - 131 - 132 - 133 - 134 - 135 - 136 - 137 - 138 - 139 - 140 - 141 - 142 - 143 - 144 - 145 - 146 - 147 - 148 - 149 - 150 - 151 - 152 - 153 - Done\n"
          ]
        }
      ],
      "source": [
        "arabic_translation_list = []\n",
        "i = 0\n",
        "for text in reviews['summary']:\n",
        "    english_text = text\n",
        "    arabic_translation = translate_ar_to_en(english_text)\n",
        "    arabic_translation_list.append(arabic_translation)\n",
        "    print(i,end=' - ')\n",
        "    i+=1\n",
        "\n",
        "reviews['translated_summary'] = arabic_translation_list\n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = pd.read_csv('translated_dataset.csv')"
      ],
      "metadata": {
        "id": "HWF9xD_rL8YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "xxKIacpiXXl7",
        "outputId": "06fdca61-58fb-4f34-b6b3-f6ac8348034c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                          paragraph  \\\n",
              "0           0  ูุชุญุช ุนููุงู ูู ุงููุงุฑุซุฉ ุฅูู ุงูุชุญุฏู ูุจุฏุฃ ุงููุงุชุจ ุน...   \n",
              "1           1  ููู ูุนุชุฑู ุฏุจูููุงุณูู ูุงุชูู ุงูุฏููุชูู ุจุงูุนุฑูุถุฉ ุงู...   \n",
              "2           2  ูุงูุช ููุงูุฉ ุญูุจ ุจุนุฏ ุงุนูุงู ุงูุฌูุฑุงู ุงููุฑูุณู ููุฑู ...   \n",
              "3           3  ุฏููุฉ ูุตุฑ ุงูุนุฑุจูู ูู ููุณุช ุงู ุฏููู ูููุณุช ุงู ุดุนุจ ...   \n",
              "4           4  ุงูุณูุฑููู ูุตุฑูู ุนูู ุงุณุชููุงู ุจูุงุฏูู : ู ูุซููุง ุฑู...   \n",
              "\n",
              "                                             summary  tokens_paragraph  \\\n",
              "0  ูุจุฏุฃ ุงููุงุชุจ ุนุฑุถ ุงููุชุงุจ ุงูุฑุงุจุน ุชุญุช ุนููุงู ูู ุงูู...               335   \n",
              "1  ุฏุจูููุงุณูู ุงูุฏููุชูู ูู ูุนุชุฑููุง ุจุงูุนุฑูุถุฉ ุงูุชู ูุง...               277   \n",
              "2  ุฃุนูู ุบูุฑู ุงูุงูุชุฏุงุจ ุงููุฑูุณู ุนูู ุณูุฑูุง ููู ูุนุงูุจ...               339   \n",
              "3  ูุตุฑ ูู ุฃู ุงูุจูุงุฏุ ููุงุฆุฏุฉ ุงูุนุฑุจุ ููู ุฃุฑุถ ุจูุงุฏ ุง...               282   \n",
              "4  ุงูุดุนุจ ุงูุณูุฑู ูุตุฑ ุนูู ุงุณุชููุงู ุจูุฏูู ูู ุงูุณูุทุฑุฉ ...               259   \n",
              "\n",
              "                                    translated_input  \\\n",
              "0  Under the title From Disaster to Challenge, th...   \n",
              "1  The diplomats of these two countries did not r...   \n",
              "2  The Wilayat of Aleppo was established after th...   \n",
              "3  The Arab state of Egypt is not any country and...   \n",
              "4  The Syrians insist on the independence of thei...   \n",
              "\n",
              "                                  translated_summary  \n",
              "0  The writer begins presenting the fourth book u...  \n",
              "1  The diplomats of the two countries did not rec...  \n",
              "2  Gouraud declared the French mandate over Syria...  \n",
              "3  Egypt is the mother of the country, and the le...  \n",
              "4  The Syrian people insist on the independence o...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31fa9e26-69f9-4beb-bbf9-4ed85a039562\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>summary</th>\n",
              "      <th>tokens_paragraph</th>\n",
              "      <th>translated_input</th>\n",
              "      <th>translated_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ูุชุญุช ุนููุงู ูู ุงููุงุฑุซุฉ ุฅูู ุงูุชุญุฏู ูุจุฏุฃ ุงููุงุชุจ ุน...</td>\n",
              "      <td>ูุจุฏุฃ ุงููุงุชุจ ุนุฑุถ ุงููุชุงุจ ุงูุฑุงุจุน ุชุญุช ุนููุงู ูู ุงูู...</td>\n",
              "      <td>335</td>\n",
              "      <td>Under the title From Disaster to Challenge, th...</td>\n",
              "      <td>The writer begins presenting the fourth book u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ููู ูุนุชุฑู ุฏุจูููุงุณูู ูุงุชูู ุงูุฏููุชูู ุจุงูุนุฑูุถุฉ ุงู...</td>\n",
              "      <td>ุฏุจูููุงุณูู ุงูุฏููุชูู ูู ูุนุชุฑููุง ุจุงูุนุฑูุถุฉ ุงูุชู ูุง...</td>\n",
              "      <td>277</td>\n",
              "      <td>The diplomats of these two countries did not r...</td>\n",
              "      <td>The diplomats of the two countries did not rec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ูุงูุช ููุงูุฉ ุญูุจ ุจุนุฏ ุงุนูุงู ุงูุฌูุฑุงู ุงููุฑูุณู ููุฑู ...</td>\n",
              "      <td>ุฃุนูู ุบูุฑู ุงูุงูุชุฏุงุจ ุงููุฑูุณู ุนูู ุณูุฑูุง ููู ูุนุงูุจ...</td>\n",
              "      <td>339</td>\n",
              "      <td>The Wilayat of Aleppo was established after th...</td>\n",
              "      <td>Gouraud declared the French mandate over Syria...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>ุฏููุฉ ูุตุฑ ุงูุนุฑุจูู ูู ููุณุช ุงู ุฏููู ูููุณุช ุงู ุดุนุจ ...</td>\n",
              "      <td>ูุตุฑ ูู ุฃู ุงูุจูุงุฏุ ููุงุฆุฏุฉ ุงูุนุฑุจุ ููู ุฃุฑุถ ุจูุงุฏ ุง...</td>\n",
              "      <td>282</td>\n",
              "      <td>The Arab state of Egypt is not any country and...</td>\n",
              "      <td>Egypt is the mother of the country, and the le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ุงูุณูุฑููู ูุตุฑูู ุนูู ุงุณุชููุงู ุจูุงุฏูู : ู ูุซููุง ุฑู...</td>\n",
              "      <td>ุงูุดุนุจ ุงูุณูุฑู ูุตุฑ ุนูู ุงุณุชููุงู ุจูุฏูู ูู ุงูุณูุทุฑุฉ ...</td>\n",
              "      <td>259</td>\n",
              "      <td>The Syrians insist on the independence of thei...</td>\n",
              "      <td>The Syrian people insist on the independence o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31fa9e26-69f9-4beb-bbf9-4ed85a039562')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31fa9e26-69f9-4beb-bbf9-4ed85a039562 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31fa9e26-69f9-4beb-bbf9-4ed85a039562');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "reviews.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOqk2XFHC20I"
      },
      "source": [
        "# Step 4: Load the Pretrained Transformer Model (mT5) on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDiE1rLCwBeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b46228f-12d6-4c1a-98c6-68a9724be41e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers[torch]\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90mโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers[torch])\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90mโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[torch])\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90mโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers[torch])\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.65.0)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)\n",
            "Collecting accelerate>=0.20.2 (from transformers[torch])\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90mโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.2->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (16.0.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers, accelerate\n",
            "Successfully installed accelerate-0.20.3 huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgL29E7KG6aR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "094895dc-2714-463f-ca27-adb883202809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[?25l     \u001b[90mโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[91mโธ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Change the names in the data to English names"
      ],
      "metadata": {
        "id": "Bm3KDHWGMitg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH0HJ7KyMh1P",
        "outputId": "064fb91b-d867-40f2-c2fc-5dea393d76f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading Faker-18.11.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[?25l     \u001b[90mโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mโโโโโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[90mโบ\u001b[0m\u001b[90mโโโโโโโโโโโโโโโ\u001b[0m \u001b[32m1.0/1.7 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[91mโธ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Installing collected packages: faker\n",
            "Successfully installed faker-18.11.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and install the large English model\n",
        "import spacy\n",
        "spacy.cli.download(\"en_core_web_lg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIi2W1weN2CY",
        "outputId": "69754038-988b-478c-90f0-df027b9fefce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2mโ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "from faker import Faker\n",
        "\n",
        "\n",
        "\n",
        "def generate_one_syllable_name(fake):\n",
        "    while True:\n",
        "        name = fake.first_name()\n",
        "        if len(name.split('-')) == 1:  # Check if the name has one syllable\n",
        "            return name\n",
        "\n",
        "\n",
        "def replace_names(sentence):\n",
        "    nlp = spacy.load('en_core_web_lg')\n",
        "    doc = nlp(sentence)\n",
        "    name_replacements = {}\n",
        "    fake = Faker()\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in ['PERSON','GPE'] and not any(token.pos_ == 'NUM' for token in ent):\n",
        "            name = ent.text\n",
        "            if name not in name_replacements:\n",
        "                replacement = generate_one_syllable_name(fake)\n",
        "                sentence = re.sub(r'\\b' + re.escape(name) + r'\\b', replacement, sentence)\n",
        "                name_replacements[name] = replacement\n",
        "\n",
        "    return sentence, name_replacements\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2YHJKqF2N8UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_names_dataset = []\n",
        "i=0\n",
        "for _, row in reviews.iterrows():\n",
        "    target_text = row['translated_summary']\n",
        "    input_text = row['translated_input']\n",
        "\n",
        "\n",
        "    # Replace names in target text\n",
        "    replaced_target_text, replacements_t = replace_names(target_text)\n",
        "\n",
        "    # Replace names in input text\n",
        "    replaced_input_text, replacements_i = replace_names(input_text)\n",
        "    i+=1\n",
        "    print(i,end=' - ')\n",
        "\n",
        "    # Save modified data\n",
        "    en_names_dataset.append({\n",
        "        'translated_summary': replaced_target_text,\n",
        "        'translated_input': replaced_input_text,\n",
        "        'input_english_names': replacements_i,\n",
        "        'target_english_names': replacements_t,\n",
        "\n",
        "    })\n",
        "\n",
        "# Create a new DataFrame with modified data\n",
        "en_names_dataset = pd.DataFrame(en_names_dataset)\n",
        "\n",
        "# Save the modified DataFrame to a new CSV file\n",
        "en_names_dataset.to_csv('en_names_dataset.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AwDLRldOJGM",
        "outputId": "523a7d63-c875-485b-9a3c-4028722a16f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - 11 - 12 - 13 - 14 - 15 - 16 - 17 - 18 - 19 - 20 - 21 - 22 - 23 - 24 - 25 - 26 - 27 - 28 - 29 - 30 - 31 - 32 - 33 - 34 - 35 - 36 - 37 - 38 - 39 - 40 - 41 - 42 - 43 - 44 - 45 - 46 - 47 - 48 - 49 - 50 - 51 - 52 - 53 - 54 - 55 - 56 - 57 - 58 - 59 - 60 - 61 - 62 - 63 - 64 - 65 - 66 - 67 - 68 - 69 - 70 - 71 - 72 - 73 - 74 - 75 - 76 - 77 - 78 - 79 - 80 - 81 - 82 - 83 - 84 - 85 - 86 - 87 - 88 - 89 - 90 - 91 - 92 - 93 - 94 - 95 - 96 - 97 - 98 - 99 - 100 - 101 - 102 - 103 - 104 - 105 - 106 - 107 - 108 - 109 - 110 - 111 - 112 - 113 - 114 - 115 - 116 - 117 - 118 - 119 - 120 - 121 - 122 - 123 - 124 - 125 - 126 - 127 - 128 - 129 - 130 - 131 - 132 - 133 - 134 - 135 - 136 - 137 - 138 - 139 - 140 - 141 - 142 - 143 - 144 - 145 - 146 - 147 - 148 - 149 - 150 - 151 - 152 - 153 - 154 - "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = pd.read_csv('en_names_dataset.csv')\n",
        "reviews.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "anGj3pKuSJia",
        "outputId": "4c669135-8f9f-438c-90e7-2ed1007e360f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  translated_summary  \\\n",
              "0  The writer begins presenting the fourth book u...   \n",
              "1  The diplomats of the two countries did not rec...   \n",
              "2  Cassandra declared the French mandate over Val...   \n",
              "3  Monique is the mother of the country, and the ...   \n",
              "4  The Syrian people insist on the independence o...   \n",
              "\n",
              "                                    translated_input  \\\n",
              "0  Under the title From Disaster to Challenge, th...   \n",
              "1  The diplomats of these two countries did not r...   \n",
              "2  The Wilayat of Stephanie was established after...   \n",
              "3  The Arab state of Emily is not any country and...   \n",
              "4  The Syrians insist on the independence of thei...   \n",
              "\n",
              "                                 input_english_names  \\\n",
              "0  {'Israel': 'Steven', 'the United Arab Republic...   \n",
              "1  {'Allal al-Fassi': 'Brittany', 'Morocco': 'Cha...   \n",
              "2  {'Aleppo': 'Stephanie', 'Henri Gouraud': 'Aaro...   \n",
              "3  {'Egypt': 'Emily', 'Morocco': 'Zachary', 'Hosn...   \n",
              "4  {'Sultan Pasha al-Atrash': 'Elizabeth', 'Jabal...   \n",
              "\n",
              "                                target_english_names  \n",
              "0  {'Israel': 'Hannah', 'Abdel Nasser': 'Brian', ...  \n",
              "1  {'Allal Al-Fassi': 'Thomas', 'Cairo': 'Karen',...  \n",
              "2  {'Gouraud': 'Cassandra', 'Syria': 'Valerie', '...  \n",
              "3  {'Egypt': 'Monique', 'Hosni Mubarak': 'Amy', '...  \n",
              "4                                 {'Syria': 'Kevin'}  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9810158e-dc58-40c2-b890-d9efb842a5c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>translated_summary</th>\n",
              "      <th>translated_input</th>\n",
              "      <th>input_english_names</th>\n",
              "      <th>target_english_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The writer begins presenting the fourth book u...</td>\n",
              "      <td>Under the title From Disaster to Challenge, th...</td>\n",
              "      <td>{'Israel': 'Steven', 'the United Arab Republic...</td>\n",
              "      <td>{'Israel': 'Hannah', 'Abdel Nasser': 'Brian', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The diplomats of the two countries did not rec...</td>\n",
              "      <td>The diplomats of these two countries did not r...</td>\n",
              "      <td>{'Allal al-Fassi': 'Brittany', 'Morocco': 'Cha...</td>\n",
              "      <td>{'Allal Al-Fassi': 'Thomas', 'Cairo': 'Karen',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cassandra declared the French mandate over Val...</td>\n",
              "      <td>The Wilayat of Stephanie was established after...</td>\n",
              "      <td>{'Aleppo': 'Stephanie', 'Henri Gouraud': 'Aaro...</td>\n",
              "      <td>{'Gouraud': 'Cassandra', 'Syria': 'Valerie', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Monique is the mother of the country, and the ...</td>\n",
              "      <td>The Arab state of Emily is not any country and...</td>\n",
              "      <td>{'Egypt': 'Emily', 'Morocco': 'Zachary', 'Hosn...</td>\n",
              "      <td>{'Egypt': 'Monique', 'Hosni Mubarak': 'Amy', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Syrian people insist on the independence o...</td>\n",
              "      <td>The Syrians insist on the independence of thei...</td>\n",
              "      <td>{'Sultan Pasha al-Atrash': 'Elizabeth', 'Jabal...</td>\n",
              "      <td>{'Syria': 'Kevin'}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9810158e-dc58-40c2-b890-d9efb842a5c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9810158e-dc58-40c2-b890-d9efb842a5c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9810158e-dc58-40c2-b890-d9efb842a5c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28X3z5INtAfO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# T5 model\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzjP3HRT33gd"
      },
      "outputs": [],
      "source": [
        "# Define your custom dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, tokenizer, data):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        input_text = str(self.data.loc[index, \"translated_input\"])\n",
        "        target_text = str(self.data.loc[index, \"translated_summary\"])\n",
        "\n",
        "        encoding = self.tokenizer.prepare_seq2seq_batch(\n",
        "            src_texts=[input_text],\n",
        "            tgt_texts=[target_text],\n",
        "            max_length=512,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding.input_ids.squeeze(),\n",
        "            \"attention_mask\": encoding.attention_mask.squeeze(),\n",
        "            \"labels\": encoding.labels.squeeze()\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2ap8pjU39k3",
        "outputId": "125f71c4-29a7-4443-d9cf-b2a4ee0f7779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Initialize the T5 tokenizer and model\n",
        "# T5\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzmEaRVIh_uy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3264a218-a7e6-4aa7-8784-893b2db61b7c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4248' max='5070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4248/5070 1:24:53 < 16:26, 0.83 it/s, Epoch 108.90/130]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.531300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.580900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.508900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.476700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.416500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.387400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.348700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.315200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.292700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.260400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.242900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.217700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.200900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.183300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.168100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.155100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.141800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.129700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.121500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.109600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.105300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.095700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.089400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.081100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.078800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.074400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.068700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.065000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.059700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.057900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.055100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.052500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.049000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.047300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.043900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.042500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.044400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.040700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.039100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.036700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.037000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.036100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3745: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3745: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3745: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3745: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3745: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3745: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3745: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3745: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5070' max='5070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5070/5070 1:41:33, Epoch 130/130]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.531300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.580900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.508900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.476700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.416500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.387400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.348700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.315200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.292700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.260400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.242900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.217700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.200900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.183300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.168100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.155100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.141800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.129700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.121500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.109600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.105300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.095700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.089400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.081100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.078800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.074400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.068700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.065000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.059700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.057900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.055100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.052500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.049000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.047300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.043900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.042500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.044400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.040700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.039100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.036700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.037000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.036100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.035600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.034500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.033300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.033400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.031900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.032600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.031900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.031200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3745: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3745: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('model_summary_arabic/tokenizer_config.json',\n",
              " 'model_summary_arabic/special_tokens_map.json',\n",
              " 'model_summary_arabic/spiece.model',\n",
              " 'model_summary_arabic/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Create your training dataset\n",
        "train_dataset = CustomDataset(tokenizer, reviews)\n",
        "\n",
        "# Set up the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./\",\n",
        "    num_train_epochs=130,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=9,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "\n",
        ")\n",
        "\n",
        "# Initialize the trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    data_collator=None\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "output_dir = \"model_summary_arabic\"\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUr7koeSLVHg"
      },
      "source": [
        "# Step 5: Load the model for inference (Predict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "C1l7ozBesfPN",
        "outputId": "58b1bac8-a77d-4d88-b2ec-8013e8bc786f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  translated_summary  \\\n",
              "0  The writer begins presenting the fourth book u...   \n",
              "1  The diplomats of the two countries did not rec...   \n",
              "2  Cassandra declared the French mandate over Val...   \n",
              "3  Monique is the mother of the country, and the ...   \n",
              "4  The Syrian people insist on the independence o...   \n",
              "\n",
              "                                    translated_input  \\\n",
              "0  Under the title From Disaster to Challenge, th...   \n",
              "1  The diplomats of these two countries did not r...   \n",
              "2  The Wilayat of Stephanie was established after...   \n",
              "3  The Arab state of Emily is not any country and...   \n",
              "4  The Syrians insist on the independence of thei...   \n",
              "\n",
              "                                 input_english_names  \\\n",
              "0  {'Israel': 'Steven', 'the United Arab Republic...   \n",
              "1  {'Allal al-Fassi': 'Brittany', 'Morocco': 'Cha...   \n",
              "2  {'Aleppo': 'Stephanie', 'Henri Gouraud': 'Aaro...   \n",
              "3  {'Egypt': 'Emily', 'Morocco': 'Zachary', 'Hosn...   \n",
              "4  {'Sultan Pasha al-Atrash': 'Elizabeth', 'Jabal...   \n",
              "\n",
              "                                target_english_names  \n",
              "0  {'Israel': 'Hannah', 'Abdel Nasser': 'Brian', ...  \n",
              "1  {'Allal Al-Fassi': 'Thomas', 'Cairo': 'Karen',...  \n",
              "2  {'Gouraud': 'Cassandra', 'Syria': 'Valerie', '...  \n",
              "3  {'Egypt': 'Monique', 'Hosni Mubarak': 'Amy', '...  \n",
              "4                                 {'Syria': 'Kevin'}  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05b043ad-0c3f-491d-817e-071b85ac4553\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>translated_summary</th>\n",
              "      <th>translated_input</th>\n",
              "      <th>input_english_names</th>\n",
              "      <th>target_english_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The writer begins presenting the fourth book u...</td>\n",
              "      <td>Under the title From Disaster to Challenge, th...</td>\n",
              "      <td>{'Israel': 'Steven', 'the United Arab Republic...</td>\n",
              "      <td>{'Israel': 'Hannah', 'Abdel Nasser': 'Brian', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The diplomats of the two countries did not rec...</td>\n",
              "      <td>The diplomats of these two countries did not r...</td>\n",
              "      <td>{'Allal al-Fassi': 'Brittany', 'Morocco': 'Cha...</td>\n",
              "      <td>{'Allal Al-Fassi': 'Thomas', 'Cairo': 'Karen',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cassandra declared the French mandate over Val...</td>\n",
              "      <td>The Wilayat of Stephanie was established after...</td>\n",
              "      <td>{'Aleppo': 'Stephanie', 'Henri Gouraud': 'Aaro...</td>\n",
              "      <td>{'Gouraud': 'Cassandra', 'Syria': 'Valerie', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Monique is the mother of the country, and the ...</td>\n",
              "      <td>The Arab state of Emily is not any country and...</td>\n",
              "      <td>{'Egypt': 'Emily', 'Morocco': 'Zachary', 'Hosn...</td>\n",
              "      <td>{'Egypt': 'Monique', 'Hosni Mubarak': 'Amy', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Syrian people insist on the independence o...</td>\n",
              "      <td>The Syrians insist on the independence of thei...</td>\n",
              "      <td>{'Sultan Pasha al-Atrash': 'Elizabeth', 'Jabal...</td>\n",
              "      <td>{'Syria': 'Kevin'}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05b043ad-0c3f-491d-817e-071b85ac4553')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05b043ad-0c3f-491d-817e-071b85ac4553 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05b043ad-0c3f-491d-817e-071b85ac4553');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XhrMNeOLxQk"
      },
      "outputs": [],
      "source": [
        "x = reviews['translated_input'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-ALmX2eL0BI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06f5975-f090-4a89-e60d-409bf379a9cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summary:  The writer begins presenting the fourth book under the title From Disaster to Challenge, where he explains how Hannah was happy with its victory in 67, and how the war of attrition began, then he talks about the death of Brian, and Rebekah took over the rule of Rebecca. He says : This day was the worst defeat in the history of the Israeli army, then he moves us to the Syrian front, then returns again to the war diaries from October 9 -7 to October 13 -9 and October 14 and October 14 and presents the breach or what was known as the American aid, then the tendency to approve the request for a cease - fire from October 17 to 20 and the final operations in the Su ez Canal from October 19 to 22 and the final operations in the Su ez Canal.\n",
            "summary:  Jennifer entered the war against Robert in October 9, then the writer presents the battle for the sei zu re of the city Su ez from October 23 to October 25, then the developments of this battle, and how, by the twenty -seventh day of October, the Israeli s had captured about eight thousand members of the Egyptian forces, most of them from the supply and supply units.\n",
            "Generated Summary: The writer begins presenting the fourth book under the title From Disaster to Challenge, where he explains how Hannah was happy with its victory in 67, and how the war of attrition began, then he talks about the death of Brian, and Rebekah took over the rule of Rebecca. He says : This day was the worst defeat in the history of the Israeli army, then he moves us to the Syrian front, then returns again to the war diaries from October 9 -7 to October 13 -9 and October 14 and October 14 and presents the breach or what was known as the American aid, then the tendency to approve the request for a cease - fire from October 17 to 20 and the final operations in the Su ez Canal from October 19 to 22 and the final operations in the Su ez Canal. Jennifer entered the war against Robert in October 9, then the writer presents the battle for the sei zu re of the city Su ez from October 23 to October 25, then the developments of this battle, and how, by the twenty -seventh day of October, the Israeli s had captured about eight thousand members of the Egyptian forces, most of them from the supply and supply units.\n"
          ]
        }
      ],
      "source": [
        "# Load the trained model and tokenizer\n",
        "model_dir = \"model_summary_arabic\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_dir)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_dir)\n",
        "\n",
        "# tokenizer = PegasusTokenizer.from_pretrained(model_dir)\n",
        "# model = PegasusForConditionalGeneration.from_pretrained(model_dir)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "eval = model.eval()\n",
        "\n",
        "# Input text\n",
        "input_text = x\n",
        "max_chunk_length = 400  # Maximum length for each chunk\n",
        "\n",
        "# Tokenize and chunk the input text\n",
        "input_tokens = tokenizer.tokenize(input_text)\n",
        "chunked_input = []\n",
        "current_chunk = []\n",
        "for token in input_tokens:\n",
        "    current_chunk.append(token)\n",
        "    if len(current_chunk) >= max_chunk_length:\n",
        "        chunked_input.append(\" \".join(current_chunk))\n",
        "        current_chunk = []\n",
        "if current_chunk:\n",
        "    chunked_input.append(\" \".join(current_chunk))\n",
        "\n",
        "# Generate summaries for each chunk\n",
        "summaries = []\n",
        "for chunk in chunked_input:\n",
        "    input_ids = tokenizer.encode(chunk, return_tensors=\"pt\")\n",
        "    output = model.generate(input_ids, max_length=300, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    print('summary: ',summary)\n",
        "    summaries.append(summary)\n",
        "\n",
        "# Combine the generated summaries\n",
        "combined_summary = \" \".join(summaries)\n",
        "\n",
        "# Print the generated summary\n",
        "print(\"Generated Summary:\", combined_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWPdWMAyLz54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c4f5bab8-156d-46ef-f67d-62c8871786b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ูุจุฏุฃ ุงููุงุชุจ ูู ุชูุฏูู ุงููุชุงุจ ุงูุฑุงุจุน ุจุนููุงู ูู ูุงุฑุซุฉ ุฅูู ุชุญุฏู ุ ุญูุซ ูุดุฑุญ ููู ูุงูุช ุญูุฉ ุณุนูุฏุฉ ุจุงูุชุตุงุฑูุง ุนุงู 67 ุ ูููู ุจุฏุฃุช ุญุฑุจ ุงูุงุณุชูุฒุงู ุ ุซู ุชุญุฏุซ ุนู ููุช ุจุฑูุงู ุ ูุชููุช ุฑุจููุง ุฒูุงู ุงูุฃููุฑ. ุญูู ุฑูุจููุง. ูููู: ูุฐุง ุงูููู ูุงู ุฃุณูุฃ ูุฒููุฉ ูู ุชุงุฑูุฎ ุงูุฌูุด ุงูุฅุณุฑุงุฆููู ุ ุซู ูููููุง ุฅูู ุงูุฌุจูุฉ ุงูุณูุฑูุฉ ุ ุซู ูุนูุฏ ูุฑุฉ ุฃุฎุฑู ุฅูู ููููุงุช ุงูุญุฑุจ ูู 9 ุฅูู 7 ุชุดุฑูู ุงูุฃูู (ุฃูุชูุจุฑ) ุญุชู 13 ุชุดุฑูู ุงูุฃูู (ุฃูุชูุจุฑ) ุ ู 14 ุชุดุฑูู ุงูุฃูู (ุฃูุชูุจุฑ) ู 14 ุชุดุฑูู ุงูุฃูู (ุฃูุชูุจุฑ) ูุนุฑุถ ุงูุฎุฑู ุฃู ูุง ูุงู ูุนุฑู ุจุงููุณุงุนุฏุงุช ุงูุฃูุฑูููุฉ ุ ุซู ุงูุชูุฌู ูุญู ุงูููุงููุฉ ุนูู ุทูุจ ููู ุฅุทูุงู ุงููุงุฑ ูู 17 ุฅูู 20 ุฃูุชูุจุฑ ูุงูุนูููุงุช ุงูููุงุฆูุฉ ูู ููุงุฉ ุงูุณููุณ ูู 19 ุฅูู 22 ุฃูุชูุจุฑ ูุงูุนูููุงุช ุงูููุงุฆูุฉ ูู ููุทูุฉ ุณู. ููุงุฉ ez. ุฏุฎูุช ุฌููููุฑ ุงูุญุฑุจ ุถุฏ ุฑูุจุฑุช ูู 9 ุฃูุชูุจุฑ ุ ุซู ูุนุฑุถ ุงููุงุชุจ ูุนุฑูุฉ ุณู ุฒู ุฑู ููุฏููุฉ ุณู ุฅูุฒ ูู 23 ุฃูุชูุจุฑ ุฅูู 25 ุฃูุชูุจุฑ ุ ุซู ุชุทูุฑุงุช ูุฐู ุงููุนุฑูุฉ ุ ูููู ุ ุจุญููู ุงูููู ุงูุณุงุจุน ูุงูุนุดุฑูู ูู ุงูุดูุฑ. ููุงูุช ุงูููุงุช ุงูุฅุณุฑุงุฆูููุฉ ูุฏ ุฃุณุฑุช ูู ุฃูุชูุจุฑ ุญูุงูู ุซูุงููุฉ ุขูุงู ุนูุตุฑ ูู ุงูููุงุช ุงููุตุฑูุฉ ุ ูุนุธููู ูู ูุญุฏุงุช ุงูุฅูุฏุงุฏ ูุงูุชูููู.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "summary = translate_en_to_ar(combined_summary)\n",
        "summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAMrKJ-ZLzwH"
      },
      "outputs": [],
      "source": [
        "# Load the trained model and tokenizer\n",
        "model_dir = \"model_summary_arabic\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_dir)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_dir)\n",
        "\n",
        "# tokenizer = PegasusTokenizer.from_pretrained(model_dir)\n",
        "# model = PegasusForConditionalGeneration.from_pretrained(model_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y91cdHFzNrOJ"
      },
      "source": [
        "append new column for \"generated_summary\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5faNmI0Lzmu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c63e6c-c629-41a7-aeae-0baf29985ed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# Set the model to evaluation mode\n",
        "eval = model.eval()\n",
        "\n",
        "# Input text\n",
        "input_text = reviews['translated_input']\n",
        "\n",
        "# Function to generate summaries\n",
        "def generate_summary(text):\n",
        "    max_chunk_length = 300  # Maximum length for each chunk\n",
        "    i=0\n",
        "    # Tokenize and chunk the input text\n",
        "    input_tokens = tokenizer.tokenize(text)\n",
        "    chunked_input = []\n",
        "    current_chunk = []\n",
        "    for token in input_tokens:\n",
        "        current_chunk.append(token)\n",
        "        if len(current_chunk) >= max_chunk_length:\n",
        "            chunked_input.append(\" \".join(current_chunk))\n",
        "            current_chunk = []\n",
        "    if current_chunk:\n",
        "        chunked_input.append(\" \".join(current_chunk))\n",
        "\n",
        "    # Generate summaries for each chunk\n",
        "    summaries = []\n",
        "    for chunk in chunked_input:\n",
        "        print(i)\n",
        "        i+=1\n",
        "        input_ids = tokenizer.encode(chunk, return_tensors=\"pt\")\n",
        "        output = model.generate(input_ids, max_length=300, num_beams=4, early_stopping=True)\n",
        "        summary = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        summaries.append(summary)\n",
        "\n",
        "    # Combine the generated summaries\n",
        "    combined_summary = \" \".join(summaries)\n",
        "    return combined_summary\n",
        "\n",
        "# Generate column \"generate summary\" in the DataFrame\n",
        "reviews['generated_summary'] = reviews['translated_input'].apply(generate_summary)\n",
        "\n",
        "reviews.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMFZgKD4PfEG"
      },
      "source": [
        "translate generated summary in new column called \"translated_generated_summary\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCs0Bv4sPmEL"
      },
      "outputs": [],
      "source": [
        "# Function to translate the generated summaries\n",
        "def translate_summary(summary):\n",
        "    input_ids = tokenizer.encode(summary, return_tensors=\"pt\")\n",
        "    translated_output = model.generate(input_ids)\n",
        "    translated_summary = tokenizer.decode(translated_output[0], skip_special_tokens=True)\n",
        "    return translated_summary\n",
        "\n",
        "reviews['translated_generated_summary'] = reviews['generated_summary'].apply(translate_summary)\n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o640ZK1zEJUU"
      },
      "source": [
        "# Step 6: Evaluation using ROUGE metrics\n",
        "+ ROUGE: (Recall-Oriented Understudy for Gisting Evaluation)\n",
        "+ used for evaluating the quality of text summarization outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZuwLl88ESMt"
      },
      "source": [
        "Initialize object from ROUGE metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5XkkGSOFCJD"
      },
      "outputs": [],
      "source": [
        "!pip install rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRLYv6ShEN2b"
      },
      "outputs": [],
      "source": [
        "rouge = Rouge()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLCvaOVOEW60"
      },
      "source": [
        "+ Prepare the references and hypotheses:\n",
        "  - column [summary] is references..\n",
        "      - Convert the reference summaries from the dataset into a list\n",
        "  - column [generated_summary] is hypotheses..\n",
        "      - Convert the generated summaries into a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqY5d27xEaPs"
      },
      "outputs": [],
      "source": [
        "references = reviews['summary'].tolist()\n",
        "hypotheses = reviews['translated_generated_summary'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ7gjHPAEcnb"
      },
      "source": [
        "- Pass hypotheses and references for method get_scores to compute the ROUGE scores:\n",
        "- avg= True >> compute average scores for all the scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XzTQ-a2EkAM"
      },
      "outputs": [],
      "source": [
        "scores = rouge.get_scores(hypotheses, references, avg=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sInoPZQKEnTC"
      },
      "source": [
        "- ROUGE-1: measures the overlap of `unigrams (single words)` between the generated summary (hypotheses) and the reference summary.\n",
        "\n",
        "- ROUGE-2: measures the overlap of `bigrams (pairs of consecutive words)` between the generated summary (hypotheses) and the reference summary.\n",
        "\n",
        "- ROUGE-L: measures the `longest common subsequence (LCS)` between the generated summary (hypotheses) and the reference summary.\n",
        "\n",
        "- Precision: ratio of the number of overlapping unigrams (ROUGE-1), bigrams (ROUGE-2) or LCS (ROUGE-L) between the generated and reference summaries to the number of unigrams or bigrams or LCS in the `generated summary`.\n",
        "\n",
        "- Recall: ratio of the number of overlapping unigrams (ROUGE-1), bigrams (ROUGE-2) or LCS (ROUGE-L) between the generated and reference summaries to the number of unigrams or bigrams or LCS in the `reference summary`.\n",
        "\n",
        "- ROUGE-1 Score: `harmonic mean` of precision and recall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQ_hckHQEq8L"
      },
      "outputs": [],
      "source": [
        "print(\"ROUGE-1: \", scores['rouge-1'])\n",
        "print(\"ROUGE-2: \", scores['rouge-2'])\n",
        "print(\"ROUGE-L: \", scores['rouge-l'])\n",
        "print(\"Precision: \", scores['rouge-1']['p'])\n",
        "print(\"Recall: \", scores['rouge-1']['r'])\n",
        "print(\"ROUGE-1 Score: \", scores['rouge-1']['f'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgSMH4-4EFhi"
      },
      "source": [
        "# Step 7: Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsPGprgEGZHv"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "output_dir = \"model_summary_arabic\"\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvEcOqBlODRX"
      },
      "source": [
        "# Step 8: Test\n",
        "  + with test dataset !!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyZ9AeRHKE2W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvbEowsi5dn0"
      },
      "source": [
        "# Final Step:\n",
        "  + create Dataframe \"translated_generated_summary\" has one column called \"summary\"\n",
        "  + convert it to jsonl file called \"predictions.jsonl\n",
        "  + compress it to zip format which will be submitted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGjj8bad5eLs"
      },
      "outputs": [],
      "source": [
        "# create DataFrame from column \"\"\n",
        "dataset_predictions= pd.DataFrame(reviews['translated_generated_summary'])\n",
        "dataset_predictions.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXK_PTA4TkEK"
      },
      "outputs": [],
      "source": [
        "# convert DataFrame to jsonl format\n",
        "dataset_predictions.to_json(\"predictions.jsonl\", lines=True, orient='records', force_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUTDZ79PUDl3"
      },
      "outputs": [],
      "source": [
        "# # Save JSON data to a file\n",
        "# json_file_path = 'predictions.jsonl'\n",
        "# with open(json_file_path, 'w') as json_file:\n",
        "#     json_file.write(dataset_predictions)\n",
        "\n",
        "# print(\"DataFrame converted to JSON and saved to\", json_file_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}